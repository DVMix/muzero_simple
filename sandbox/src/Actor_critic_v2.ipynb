{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af9b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bezier\n",
    "import timm\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db87baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels, kernell_size, batch_norm=None,\n",
    "               drop_out_rate=None, max_pool=None):\n",
    "    block_list = [nn.Conv2d(in_channels, out_channels, kernel_size=kernell_size, stride=1)]\n",
    "\n",
    "    if batch_norm:\n",
    "        block_list.append(nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    block_list.append(nn.LeakyReLU())\n",
    "\n",
    "    if drop_out_rate:\n",
    "        block_list.append(nn.Dropout2d(p=drop_out_rate))\n",
    "\n",
    "    if max_pool:\n",
    "        block_list.append(nn.MaxPool2d(max_pool, stride=max_pool))\n",
    "\n",
    "    return block_list\n",
    "\n",
    "\n",
    "def linear_block(input_dim, output_dim, batch_norm=None, drop_out_rate=None):\n",
    "    \n",
    "    block_list = [nn.Linear(input_dim, output_dim, bias=True)]\n",
    "    \n",
    "    if batch_norm:\n",
    "        block_list.append(nn.BatchNorm1d(num_features=output_dim))\n",
    "\n",
    "    block_list.append(nn.LeakyReLU())\n",
    "\n",
    "    if drop_out_rate:\n",
    "        block_list.append(nn.Dropout1d(p=drop_out_rate))\n",
    "\n",
    "    return block_list\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, output_size, conv_layers, linear_layers=None, adaptive_pooling_size=16):\n",
    "        \"\"\"\n",
    "        name (str): timm model name, e.g. tf_efficientnet_b2_ns\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        layers_list = []\n",
    "        for key, val in conv_layers.items():\n",
    "            layers_list += conv_block(val['in_channels'], val['out_channels'], val['kernell_size'],\n",
    "                                      val['batch_norm'], val['drop_out_rate'], val['max_pool'])\n",
    "\n",
    "        layers_list = nn.Sequential(*layers_list)\n",
    "        self.conv_blocks = nn.ModuleList(layers_list)\n",
    "        self.conv_output_channels = val['out_channels']\n",
    "        \n",
    "        self.adapt = nn.AdaptiveMaxPool2d((adaptive_pooling_size, adaptive_pooling_size))\n",
    "        \n",
    "        if linear_layers:\n",
    "            layers_list = []\n",
    "            for n, (key, val) in enumerate(linear_layers.items()):\n",
    "                if n == 0:\n",
    "                    layers_list += linear_block(self.conv_output_channels*adaptive_pooling_size**2, \n",
    "                                                val['output_dim'], val['batch_norm'], val['drop_out_rate'])\n",
    "                else:\n",
    "                    layers_list += linear_block(val['input_dim'], val['output_dim'], \n",
    "                                                val['batch_norm'], val['drop_out_rate'])\n",
    "            conv_output_size = val['output_dim']  \n",
    "            \n",
    "            layers_list = nn.Sequential(*layers_list)\n",
    "            self.linear_blocks = nn.ModuleList(layers_list)\n",
    "            \n",
    "        else:        \n",
    "            conv_output_size = adaptive_pooling_size**2\n",
    "        \n",
    "        self.output_point_one = nn.Linear(conv_output_size, output_size)\n",
    "        self.output_point_two = nn.Linear(conv_output_size + output_size, output_size)\n",
    "        self.value = nn.Linear(conv_output_size + 2*output_size, 1)\n",
    "        self.output_activation = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        for block in self.conv_blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        x = self.adapt(x)\n",
    "        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
    "        \n",
    "        if linear_layers:\n",
    "            for block in self.linear_blocks:\n",
    "                x = block(x)\n",
    "\n",
    "        point_one_policy = self.output_point_one(x)\n",
    "        \n",
    "        x = torch.cat((x, point_one_policy), dim=1)\n",
    "        point_two_policy = self.output_point_two(x)\n",
    "        \n",
    "        x = torch.cat((x, point_two_policy), dim=1)\n",
    "        value = self.value(x)\n",
    "        \n",
    "        point_one_policy  = self.output_activation(point_one_policy)\n",
    "        point_two_policy  = self.output_activation(point_two_policy)\n",
    "        \n",
    "        return {'point_one_policy': point_one_policy, 'point_two_policy': point_two_policy, 'value': value}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8954d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 32\n",
    "\n",
    "conv_layers = {\n",
    "    \n",
    "                'layer_1': {'in_channels': 2,\n",
    "                             'out_channels': 4,\n",
    "                             'kernell_size': (3, 3),\n",
    "                             'batch_norm': None,\n",
    "                             'drop_out_rate': 0.2,\n",
    "                             'max_pool': None},\n",
    "                \n",
    "                'layer_2': {'in_channels': 4,\n",
    "                             'out_channels': 8,\n",
    "                             'kernell_size': (3, 3),\n",
    "                             'batch_norm': None,\n",
    "                             'drop_out_rate': 0.2,\n",
    "                             'max_pool': None},\n",
    "    \n",
    "                'layer_3': {'in_channels': 8,\n",
    "                             'out_channels': 16,\n",
    "                             'kernell_size': (3, 3),\n",
    "                             'batch_norm': None,\n",
    "                             'drop_out_rate': 0.2,\n",
    "                             'max_pool': None}\n",
    "                }\n",
    "\n",
    "\n",
    "linear_layers = {\n",
    "    \n",
    "                'layer_1': {'input_dim': None,\n",
    "                            'output_dim': 100,\n",
    "                            'drop_out_rate': 0.2,\n",
    "                            'batch_norm': None},\n",
    "                \n",
    "                'layer_2': {'input_dim': 100,\n",
    "                            'output_dim': 100,\n",
    "                            'drop_out_rate': 0.2,\n",
    "                            'batch_norm': None},\n",
    "    \n",
    "                'layer_3': {'input_dim': 100,\n",
    "                            'output_dim': 100,\n",
    "                            'drop_out_rate': 0.2,\n",
    "                            'batch_norm': None}\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "model = Model(INPUT_SIZE*INPUT_SIZE, conv_layers, linear_layers)\n",
    "model.to(device)\n",
    "\n",
    "img_torch = torch.rand(1, 2, INPUT_SIZE, INPUT_SIZE).float().to(device)\n",
    "x = model.forward(img_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_curve_to_image(img, points, cx=1):\n",
    "    for t in np.arange(0, 1, 0.01):\n",
    "        x_curve = ((1 - t)**2*points[0][0] + 2*t*(1 - t)*points[0][1] + t**2*points[0][2])\n",
    "        #x_curve = (1 - t)*points[0] + t*points[1]\n",
    "        x_curve = int(np.floor(x_curve))\n",
    "        y_curve = ((1 - t)**2*points[0][3] + 2*t*(1 - t)*points[0][4] + t**2*points[0][5])\n",
    "        #y_curve = (1 - t)*points[2] + t*points[3]\n",
    "        y_curve = int(np.floor(y_curve)) \n",
    "        img[y_curve, x_curve] = cx\n",
    "                \n",
    "    return img\n",
    "\n",
    "def calc_loss(img, aim_image):\n",
    "    loss = np.mean(np.power(aim_image - img, 2))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_reward(loss, prev_loss):\n",
    "    if loss < prev_loss:\n",
    "        reward = (prev_loss - loss) / prev_loss\n",
    "    else:\n",
    "        reward = (prev_loss - loss) / loss\n",
    "        \n",
    "    return reward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ad7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32\n",
    "AGENTS_NUM = 5\n",
    "SCEN_NUM = 1000\n",
    "HORIZONT = 5\n",
    "GAMMA = 0.1\n",
    "ENTROPY_COEFF = 0.5\n",
    "\n",
    "\n",
    "conv_layers = {\n",
    "    \n",
    "                'layer_1': {'in_channels': 2,\n",
    "                             'out_channels': 4,\n",
    "                             'kernell_size': (3, 3),\n",
    "                             'batch_norm': None,\n",
    "                             'drop_out_rate': 0.2,\n",
    "                             'max_pool': None},\n",
    "                \n",
    "                'layer_2': {'in_channels': 4,\n",
    "                             'out_channels': 8,\n",
    "                             'kernell_size': (3, 3),\n",
    "                             'batch_norm': None,\n",
    "                             'drop_out_rate': 0.2,\n",
    "                             'max_pool': None},\n",
    "    \n",
    "                'layer_3': {'in_channels': 8,\n",
    "                             'out_channels': 16,\n",
    "                             'kernell_size': (3, 3),\n",
    "                             'batch_norm': None,\n",
    "                             'drop_out_rate': 0.2,\n",
    "                             'max_pool': None}\n",
    "                }\n",
    "\n",
    "\n",
    "linear_layers = {\n",
    "    \n",
    "                'layer_1': {'input_dim': None,\n",
    "                            'output_dim': 100,\n",
    "                            'drop_out_rate': 0.2,\n",
    "                            'batch_norm': None},\n",
    "                \n",
    "                'layer_2': {'input_dim': 100,\n",
    "                            'output_dim': 100,\n",
    "                            'drop_out_rate': 0.2,\n",
    "                            'batch_norm': None},\n",
    "    \n",
    "                'layer_3': {'input_dim': 100,\n",
    "                            'output_dim': 100,\n",
    "                            'drop_out_rate': 0.2,\n",
    "                            'batch_norm': None}\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "model = Model(IMG_SIZE*IMG_SIZE, conv_layers, linear_layers)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "history_loss = []\n",
    "history_agent_reward = []\n",
    "history_agent_loss = []\n",
    "actor_component_loss = []\n",
    "value_component_loss = []\n",
    "entropy_component_loss = []\n",
    "for scen in tqdm(range(SCEN_NUM)):\n",
    "    \n",
    "    scen_flag = True\n",
    "    aim_images_list = []\n",
    "    pred_images_list = []\n",
    "    prev_loss_list = []\n",
    "    for x in range(AGENTS_NUM):\n",
    "        img = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.float32)\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        start_line = int(np.random.rand()*2)\n",
    "        #start_line = 0\n",
    "        for i in range(0, IMG_SIZE, int(IMG_SIZE/10)):\n",
    "            img[(start_line + i) : (start_line + i + 1), :] = 1\n",
    "        \n",
    "        #img[32, :] = 1\n",
    "        \n",
    "        aim_images_list.append(np.copy(img))\n",
    "        aim_img = np.copy(img)\n",
    "        \n",
    "        img = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.float32)\n",
    "        img = img.astype(np.float32)\n",
    "        pred_images_list.append(img)\n",
    "            \n",
    "        prev_loss_list.append(calc_loss(img, aim_img))\n",
    "            \n",
    "    agent_status_list = [True for x in range(AGENTS_NUM)]\n",
    "    \n",
    "    scen_res_dict = dict()\n",
    "    \n",
    "    t = 0\n",
    "    while scen_flag:\n",
    "        \n",
    "        scen_res_dict[t] = list()\n",
    "        for x in range(AGENTS_NUM):\n",
    "             scen_res_dict[t].append(dict()) \n",
    "            \n",
    "        for ag in range(AGENTS_NUM):\n",
    "            \n",
    "            if agent_status_list[ag]:\n",
    "                \n",
    "                img_torch = torch.zeros(1, 2, IMG_SIZE, IMG_SIZE).float().to(device)\n",
    "                img_torch[0, 0, :, :] = torch.tensor(aim_images_list[ag])\n",
    "                img_torch[0, 1, :, :] = torch.tensor(np.copy(pred_images_list[ag]))\n",
    "                img_torch.to(device)\n",
    "                \n",
    "                model_output = model.forward(img_torch)\n",
    "\n",
    "                point_one_policy = torch.max(model_output['point_one_policy'])\n",
    "                point_two_policy = torch.max(model_output['point_two_policy'])\n",
    "\n",
    "                policy = point_one_policy*point_two_policy\n",
    "                log_policy = torch.log(policy)\n",
    "\n",
    "                point_one_index = int(torch.argmax(model_output['point_one_policy']))\n",
    "                point_two_index = int(torch.argmax(model_output['point_two_policy']))\n",
    "\n",
    "                point_one_Y_coord = point_one_index // IMG_SIZE\n",
    "                point_one_X_coord = point_one_index - point_one_Y_coord*IMG_SIZE\n",
    "\n",
    "                point_two_Y_coord = point_two_index // IMG_SIZE\n",
    "                point_two_X_coord = point_two_index - point_two_Y_coord*IMG_SIZE\n",
    "\n",
    "                entropy = torch.matmul(torch.transpose(model_output['point_one_policy'], 0, 1), model_output['point_two_policy'])\n",
    "                entropy = torch.sum(entropy*torch.log(entropy))\n",
    "                #entropy = 0\n",
    "                \n",
    "                points = [point_one_X_coord, point_two_X_coord, point_one_Y_coord, point_two_X_coord]\n",
    "\n",
    "                pred_img = np.copy(pred_images_list[ag])\n",
    "                pred_img = add_curve_to_image(pred_img, points)\n",
    "                \n",
    "                \n",
    "                loss = calc_loss(pred_img, aim_images_list[ag])\n",
    "                reward = calc_reward(loss, prev_loss_list[ag], points)\n",
    "    \n",
    "                scen_res_dict[t][ag]['log_policy'] = log_policy\n",
    "                scen_res_dict[t][ag]['value'] = model_output['value']\n",
    "                scen_res_dict[t][ag]['reward'] = reward\n",
    "                scen_res_dict[t][ag]['entropy'] = entropy\n",
    "                scen_res_dict[t][ag]['active_agent_flag'] = True\n",
    "                scen_res_dict[t][ag]['image_loss'] = loss\n",
    "                \n",
    "                pred_images_list[ag] = pred_img \n",
    "                prev_loss_list[ag] = loss\n",
    "                    \n",
    "                \n",
    "                \n",
    "        #if ((t % HORIZONT) == 0) & (t != 0):\n",
    "        if t >  HORIZONT:\n",
    "            #print('====================================================================')\n",
    "            #print(t)\n",
    "            loss_list = list()\n",
    "            #actor_loss = torch.empty(1)\n",
    "            #critic_loss = torch.empty(1)\n",
    "            for ag in range(AGENTS_NUM):\n",
    "                if agent_status_list[ag]:\n",
    "                    \n",
    "                    t0 = t - HORIZONT + 1\n",
    "                    G_t = 0\n",
    "                    for k in range(t0, t):\n",
    "                        reward = scen_res_dict[k][ag]['reward']\n",
    "                        G_t = G_t + GAMMA**(k - t0)*reward\n",
    "\n",
    "                    G_t = G_t + GAMMA**(t-t0)*scen_res_dict[t][ag]['value']\n",
    "                    Advantage = G_t - scen_res_dict[t0][ag]['value']\n",
    "                    \n",
    "                    actor_loss = Advantage*scen_res_dict[t0][ag]['log_policy']\n",
    "                    critic_loss = Advantage*scen_res_dict[t0][ag]['value']\n",
    "                    #critic_loss = -(G_t - scen_res_dict[t0][ag]['value'])**2\n",
    "                    entropy = scen_res_dict[t0][ag]['entropy']\n",
    "\n",
    "                    loss = -(actor_loss + critic_loss + ENTROPY_COEFF*entropy)\n",
    "                    loss = -(actor_loss + ENTROPY_COEFF*entropy)\n",
    "                    loss_list.append(loss)\n",
    "                    \n",
    "                    print(t, ag)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    if ag == 0:\n",
    "                        actor_component_loss.append(float(actor_loss.cpu().detach().numpy()))\n",
    "                        value_component_loss.append(float(critic_loss.cpu().detach().numpy()))\n",
    "                        entropy_component_loss.append(float(entropy.cpu().detach().numpy()))\n",
    "                    \n",
    "                    \n",
    "                    if scen_res_dict[t][ag]['image_loss'] < 0.01:\n",
    "                        agent_status_list[ag] = False    \n",
    "            \n",
    "            history_loss.append(float(loss.cpu().detach().numpy()))\n",
    "        \n",
    "        history_agent_reward.append(scen_res_dict[t][0]['reward']) \n",
    "        history_agent_loss.append(scen_res_dict[t][0]['image_loss']) \n",
    "            \n",
    "        if t > 20:\n",
    "            scen_flag = False\n",
    "            \n",
    "        k = 0\n",
    "        for ag in range(AGENTS_NUM):\n",
    "            if not agent_status_list[ag]:\n",
    "                k += 1\n",
    "                \n",
    "        if k == AGENTS_NUM:\n",
    "            scen_flag = False\n",
    "            \n",
    "        t += 1\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
